{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、总结下一般的英文文本预处理流程？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw_Text->Tokenize->Lemma/Stemming->stopwords->Word_List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、写下TFIDF中TF和IDF分别代表什么含义？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF(t) = (t出现在文档中的次数) / (文档中的term总数).\n",
    "IDF(t) = log_e(文档总数 / 含有t的文档总数)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、计算TFIDF值？\n",
    "写下TFIDF计算公式，并手动或调库计算每句话中单词 \"first\" 的TFIDF值。？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['this is the first document.',\n",
    "      'this is the second second document.',\n",
    "      'and the third one.',\n",
    "      'is first the third document?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF(t) = (t出现在文档中的次数) / (文档中的term总).\n",
    "IDF(t) = log_e(文档总数 / 含有t的文档总数).\n",
    "1/5*log(4/2)\n",
    "0/5*log(4/2)\n",
    "0/4*log(4/2)\n",
    "1/5*log(4/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、文本有哪些向量表示方法？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1,转换为tf-idf向量\n",
    "2，one-hot编码\n",
    "3，word2vec\n",
    "4，bag of word\n",
    "5，其他神经网络编码如BERT可将文本直接转换为定长768的向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、文本格式的数据是怎么处理成CNN网络需要的输入格式的？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1，将文本转换为2d图片模式\n",
    "先进行数据预处理，分词\n",
    "将每个词通过word2vec转换为向量，将文字转换为向量，多行文本可以看作2d的向量矩阵\n",
    "2，cnn转换为1d，通过filter将2d输入转为句子的1d的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 6、LSTM三个门的作用分别是什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "遗忘门：用来处理过去已经记住的记忆有多少需要忘记\n",
    "输入门：处理当前输入的信息，有多少需要融合到记忆中\n",
    "输出门：控制最终输出多少记忆。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7、基于专家系统或知识网络的chatbot一般属于下面哪种分类？\n",
    "\n",
    "A Retrieval-based model\n",
    "\n",
    "B Generative model\n",
    "\n",
    "C 以上都不是"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8、开放域的chatbot是否可以用 Retrieval-based model 方法实现？\n",
    "\n",
    "A 能\n",
    "\n",
    "B 不能\n",
    "\n",
    "C 不确定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B 其实只要你硬件条件允许，构造一个足够大的系统，理论上可以，只是实际无法做到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 9、简答题：VQA(视觉问答)是什么？它的输入和输出是什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "输入为图片和问题文本，输出答案文本\n",
    "可以自动理解图片中的信息及问题的语义信息，并自动将答案的信息生成为文本格式输出\n",
    "是一种结合cv与nlp的问答系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 10、简答题：VQA 基本建模方法？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "1,处理输入源数据：图片、文字。\n",
    "把图片通过深度网络如vgg16 变为feature表示的向量，\n",
    "把文字内容(基于Rule-Based、Word Vector或RNN，LSTM,BERT)转换为feature表示的向量\n",
    "\n",
    "2,选取VQA模型-MLP、选取VQA模型-LSTM：把上一步图片和文字的输出结果，经过处理如直接拼接后，输入到MLP模型。用倒三角分类为1000维数组，概率最高作为最终答案。\n",
    "\n",
    "3,生成答案：选取答案。从VQA中选取最可能的答案，把生成答案的开放域转为选取答案的封闭域，再进行词频数组降维。\n",
    "\n",
    "课程内容太旧了，vqa已经不是现在的研究热门了\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
