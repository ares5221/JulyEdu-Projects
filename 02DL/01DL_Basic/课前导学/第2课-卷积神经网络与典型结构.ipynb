{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <Center>本节课知识点提炼</Center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本节课重点与难点\n",
    "* 重点：卷积神经网络层级机构、Dropout\n",
    "* 难点：Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.神经网络与卷积神经网络 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在计算机视觉中，图像参数量剧增，不适合用DNN来处理，所以引入了卷积神经网络CNN。  \n",
    "\n",
    "#### 1).层级结构    \n",
    "* 数据 输入层/Input layer   \n",
    "    -去均值: 把输入数据各个维度都中心化到0   \n",
    "    -归一化: 幅度归一化到同样的范围 (减去均值除以方差)  \n",
    "    -PCA: PCA降维  \n",
    "    -白化: 对数据每个特征轴上的幅度归一化  \n",
    "    \n",
    "* 卷积计算层/CONV layer   \n",
    "  局部关联：每个神经元看做是一个filter  \n",
    "  窗口滑动：filter对局部数据计算  \n",
    "  输出大小计算公式：$\\frac{W-F+2P}{S} + 1 $ ：F：卷积核大小，S:卷积步长  \n",
    "  参数共享：每个神经元链接数据窗口的权重是固定的；同一个卷积核在整张特征层上卷积时其参数保持不变。  \n",
    "  卷积：一组固定的权重和不同窗口内数据做内积  \n",
    "  \n",
    "* 激励层/Activation layer    \n",
    "  把卷积层输出结果做非线性映射  \n",
    "  常见的激活函数有：  \n",
    "    Sigmoid   \n",
    "    Tanh   \n",
    "    ReLU  \n",
    "    Leaky ReLU  \n",
    "    ELU  \n",
    "    Maxout   \n",
    "\n",
    "* 池化层/Pooling layer   \n",
    "   池化层在连续的卷积层之间、压缩数据和参数的量，减小过拟合.  \n",
    "   Max Pooling: 取最大值   \n",
    "   Average Pooling：取平均值  \n",
    "   \n",
    "* 全连接层/FC layer   \n",
    "   两层之间所有神经元都有权重连接、通常全连接层在卷积神经网络尾部  \n",
    "   典型的CNN结构为：\n",
    "   INPUT -> [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC  \n",
    "   \n",
    "   \n",
    "* Batch Normalization层(不是必须的)   \n",
    "    使得模型训练收敛的速度更快、模型隐藏输出特征的分布更稳定，更利于模型的学习\n",
    "\n",
    "#### 4).优缺点   \n",
    "    \n",
    "* 优点  \n",
    "    共享卷积核，优化计算量;  \n",
    "    无需手动选取特征，训练好权重，即得特征;  \n",
    "    深层次的网络抽取图像信息丰富，表达效果好;   \n",
    "* 缺点  \n",
    "    需要调参，需要大样本量，GPU等硬件依赖；  \n",
    "    物理含义不明确；  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Dropout "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Droup来源：  \n",
    "\n",
    "        在2012年，Hinton在其论文《Improving neural networks by preventing co-adaptation of feature detectors》中提出Dropout。当一个复杂的前馈神经网络被训练在小的数据集时，容易造成过拟合。为了防止过拟合，可以通过阻止特征检测器的共同作用来提高神经网络的性能。  \n",
    "        同年，Alex、Hinton在其论文《ImageNet Classification with Deep Convolutional Neural Networks》中用到了Dropout算法，用于防止过拟合。并且，这篇论文提到的AlexNet网络模型引爆了神经网络应用热潮，并赢得了2012年图像识别大赛冠军，使得CNN成为图像分类上的核心算法模型。  \n",
    "       随后，又有一些关于Dropout的文章《Dropout:A Simple Way to Prevent Neural Networks from Overfitting》、《Improving Neural Networks with Dropout》、《Dropout as data augmentation》。\n",
    "       Dropout可以作为训练深度神经网络的一种trick供选择。在每个训练batch中，通过忽略一半的特征检测器(让一半的隐层节点值为0)，可以明显地减少过拟合现象。这种方式可以减少特征检测器（隐层节点）间的相互作用。  \n",
    "       \n",
    "    简单概括就是：在前向传播的时，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征.\n",
    "\n",
    "Dropout可以解决过拟合的原因：  \n",
    "* 取平均：不用Dropout时，用相同的训练数据去训练5个不同的神经网络，一般会得到5个不同的结果，此时我们可以采用 “5个结果取均值”或者“多数取胜的投票策略”去决定最终结果。例如3个网络判断结果为数字9,那么很有可能真正的结果就是数字9，其它两个网络给出了错误结果。这种“综合起来取平均”的策略通常可以有效防止过拟合问题。因为不同的网络可能产生不同的过拟合，取平均则有可能让一些“相反的”拟合互相抵消。Dropout掉不同的隐藏神经元就类似在训练不同的网络，随机删掉一半隐藏神经元导致网络结构已经不同，整个Dropout过程就相当于对很多个不同的神经网络取平均。而不同的网络产生不同的过拟合，一些互为“反向”的拟合相互抵消就可以达到整体上减少过拟合。\n",
    "\n",
    "* 减少神经元之间复杂的共适应关系： 因为Dropout导致两个神经元不一定每次都在网络中出现,这样权值的更新不再依赖于有固定关系的隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况; 迫使网络去学习更加鲁棒的特征。假如我们的神经网络是在做出某种预测，它不应该对一些特定的线索片段太过敏感，即使丢失特定的线索，它也应该可以从众多其它线索中学习一些共同的特征。\n",
    "\n",
    "Dropout值一般选择0.3或0.5，可以根据实际情况选择; Dropout只在训练时使用，模型训练好以后测试时不需要设置Dropout.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.典型结构 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LeNet，这是最早用于数字识别的CNN; [论文链接](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)\n",
    "* AlexNet，2012 ILSVRC比赛远超第2名的CNN，比LeNet更深，用多层小卷积层叠加替换单大卷积层; [论文链接](https://wmathor.com/usr/uploads/2019/05/3327542327.pdf)\n",
    "* ZF Net，2013 ILSVRC比赛冠军;  [论文链接](https://arxiv.org/pdf/1311.2901.pdf)\n",
    "* GoogLeNet，2014 ILSVRC比赛冠军;  [论文链接](https://arxiv.org/abs/1409.4842)\n",
    "* VGGNet，2014 ILSVRC比赛中的模型，图像识别略差于GoogLeNet，但是在很多图像转化学习问题(比如object detection)上效果很好; [论文链接](https://arxiv.org/pdf/1409.1556.pdf)\n",
    "* ResNet，2015ILSVRC比赛冠军，结构修正(残差学习)以适应深层次CNN训练; [论文链接](https://arxiv.org/abs/1512.03385)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
