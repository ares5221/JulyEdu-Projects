{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <Center>本节课知识点提炼</Center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本节课重点与难点\n",
    "* 重点：TensorFlow基本使用\n",
    "* 难点：Caffe的使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 深度学习框架与应用\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Caffe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特点  \n",
    "* 来源于Berkeley的开源框架\n",
    "* 高效、一般的训练无需手写大量代码\n",
    "* 有python和mathlab的接口\n",
    "* 对于卷积神经网络的训练和fine-tuning非常方便\n",
    "\n",
    "#### 安装  \n",
    "* Ubuntu 14.04+的同学请参考手把手教程  [链接](https://www.zybuluo.com/hanxiaoyang/note/364737 )\n",
    " \n",
    "* CentOS 7.0+的同学请参考手把手教程  [链接](https://www.zybuluo.com/hanxiaoyang/note/364680)\n",
    "\n",
    "* Mac的同学可以参考 [链接](https://www.zybuluo.com/hanxiaoyang/note/370344)\n",
    "\n",
    "* Ubuntu >=17.04下快速配置Caffe  [教程链接](http://caffe.berkeleyvision.org/install_apt.html)   \n",
    "    CPU版本:sudo apt install caffe-cpu  \n",
    "    GPU版本:sudo apt install caffe-cuda\n",
    "    \n",
    "#### Caffe官方实践-Training LeNet on MNIST with Caffe [教程链接](http://caffe.berkeleyvision.org/gathered/examples/mnist.html)  \n",
    "\n",
    "1) 准备数据  \n",
    "MNIST数据路径： \\$ CAFFE_ROOT/data/mnist/     \n",
    "cd \\\\$CAFFE_ROOT  \n",
    "#运行shell命令获取MNIST数据  \n",
    "./data/mnist/get_mnist.sh    \n",
    "#将数据转换格式为LMDB数据库格式  \n",
    "./examples/mnist/create_mnist.sh  \n",
    "2) 配置网络结构  \n",
    "官网提供了定义好的网络文件 \\$CAFFE_ROOT/examples/mnist/lenet_train_test.prototxt   \n",
    "内容如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name: \"LeNet\"  \n",
    "layer {  \n",
    "  name: \"mnist\"  \n",
    "  type: \"Data\" #数据层  \n",
    "  top: \"data\"   \n",
    "  top: \"label\"  \n",
    "  include {  \n",
    "    phase: TRAIN #训练时才加载  \n",
    "  }  \n",
    "  transform_param {  \n",
    "    scale: 0.00390625 #每个像素乘以改值做归一化（1/255 = 0.00390625）  \n",
    "  }  \n",
    "  data_param {  \n",
    "    source: \"examples/mnist/mnist_train_lmdb\" #前面生成的训练数据集  \n",
    "    batch_size: 64 # 每一批训练集大小  \n",
    "    backend: LMDB #数据格式  \n",
    "  }  \n",
    "}  \n",
    "layer {  \n",
    "  name: \"mnist\"    \n",
    "  type: \"Data\" #数据层  \n",
    "  top: \"data\"  \n",
    "  top: \"label\"  \n",
    "  include {  \n",
    "    phase: TEST #测试时才加载  \n",
    "  }  \n",
    "  transform_param {  \n",
    "    scale: 0.00390625  \n",
    "  }  \n",
    "  data_param {  \n",
    "    source: \"examples/mnist/mnist_test_lmdb\" #前面生成的测试数据集  \n",
    "    batch_size: 100  \n",
    "    backend: LMDB  \n",
    "  }  \n",
    "}  \n",
    "layer {  \n",
    "  name: \"conv1\"  \n",
    "  type: \"Convolution\" #卷积层  \n",
    "  bottom: \"data\"  \n",
    "  top: \"conv1\"  \n",
    "  param {  \n",
    "    lr_mult: 1 #weights学习率  \n",
    "  }  \n",
    "  param {  \n",
    "    lr_mult: 2 #bias学习率  \n",
    "  }  \n",
    "  convolution_param {  \n",
    "    num_output: 20 #输出多少个特征图（对应卷积核数量）  \n",
    "    kernel_size: 5 #卷积核大小  \n",
    "    stride: 1 #步长  \n",
    "    weight_filler {  \n",
    "      type: \"xavier\" #权重初始化算法  \n",
    "    }  \n",
    "    bias_filler {  \n",
    "      type: \"constant\" #基值初始化算法  \n",
    "    }  \n",
    "  }  \n",
    "}  \n",
    "layer {  \n",
    "  name: \"pool1\"  \n",
    "  type: \"Pooling\" #池化层  \n",
    "  bottom: \"conv1\"   \n",
    "  top: \"pool1\"  \n",
    "  pooling_param {  \n",
    "    pool: MAX #池化方法  \n",
    "    kernel_size: 2  \n",
    "    stride: 2  \n",
    "  }  \n",
    "}  \n",
    "layer {  \n",
    "  name: \"conv2\"  \n",
    "  type: \"Convolution\"  \n",
    "  bottom: \"pool1\"  \n",
    "  top: \"conv2\"  \n",
    "  param {  \n",
    "    lr_mult: 1  \n",
    "  }  \n",
    "  param {  \n",
    "    lr_mult: 2  \n",
    "  }  \n",
    "  convolution_param {  \n",
    "    num_output: 50  \n",
    "    kernel_size: 5  \n",
    "    stride: 1  \n",
    "    weight_filler {  \n",
    "      type: \"xavier\"  \n",
    "    }  \n",
    "    bias_filler {  \n",
    "      type: \"constant\"  \n",
    "    }  \n",
    "  }  \n",
    "}  \n",
    "layer {  \n",
    "  name: \"pool2\"  \n",
    "  type: \"Pooling\"  \n",
    "  bottom: \"conv2\"  \n",
    "  top: \"pool2\"  \n",
    "  pooling_param {  \n",
    "    pool: MAX  \n",
    "    kernel_size: 2  \n",
    "    stride: 2  \n",
    "  }  \n",
    "}  \n",
    "layer {  \n",
    "  name: \"ip1\"  \n",
    "  type: \"InnerProduct\" #全链接层  \n",
    "  bottom: \"pool2\"  \n",
    "  top: \"ip1\"  \n",
    "  param {  \n",
    "    lr_mult: 1 #weights学习率  \n",
    "  }  \n",
    "  param {  \n",
    "    lr_mult: 2 #bias学习率  \n",
    "  }  \n",
    "  inner_product_param {  \n",
    "    num_output: 500  \n",
    "    weight_filler {  \n",
    "      type: \"xavier\"  \n",
    "    }  \n",
    "    bias_filler {  \n",
    "      type: \"constant\"  \n",
    "    }  \n",
    "  }  \n",
    "}  \n",
    "layer {  \n",
    "  name: \"relu1\"  \n",
    "  type: \"ReLU\" #relu层  \n",
    "  bottom: \"ip1\"  \n",
    "  top: \"ip1\"  \n",
    "}  \n",
    "layer {  \n",
    "  name: \"ip2\"  \n",
    "  type: \"InnerProduct\"  \n",
    "  bottom: \"ip1\"  \n",
    "  top: \"ip2\"  \n",
    "  param {  \n",
    "    lr_mult: 1  \n",
    "  }  \n",
    "  param {  \n",
    "    lr_mult: 2  \n",
    "  }  \n",
    "  inner_product_param {  \n",
    "    num_output: 10  \n",
    "    weight_filler {  \n",
    "      type: \"xavier\"  \n",
    "    }  \n",
    "    bias_filler {  \n",
    "      type: \"constant\"  \n",
    "    }  \n",
    "  }  \n",
    "}  \n",
    "layer {  \n",
    "  name: \"accuracy\"  \n",
    "  type: \"Accuracy\" #输出精度  \n",
    "  bottom: \"ip2\"  \n",
    "  bottom: \"label\"  \n",
    "  top: \"accuracy\"  \n",
    "  include {  \n",
    "    phase: TEST  \n",
    "  }  \n",
    "}  \n",
    "layer {  \n",
    "  name: \"loss\"   \n",
    "  type: \"SoftmaxWithLoss\" #输出损失  \n",
    "  bottom: \"ip2\"  \n",
    "  bottom: \"label\"  \n",
    "  top: \"loss\"  \n",
    "}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以用官方自带的python绘图工具绘制出网络图  \n",
    "./caffe/python/draw_net.py ./caffe/examples/mnist/lenet_train_test.prototxt ./lenet_train_test.png  \n",
    "    在当前路径下生成lenet_train_test.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)配置网络参数  \n",
    "官网给出了参数配置文件：\\$CAFFE_ROOT/examples/mnist/lenet_solver.prototxt   \n",
    "\n",
    "    #The train/test net protocol buffer definition  \n",
    "    net: \"examples/mnist/lenet_train_test.prototxt\"  \n",
    "    #test_iter specifies how many forward passes the test should carry out.  \n",
    "    #In the case of MNIST, we have test batch size 100 and 100 test iterations,  \n",
    "    #covering the full 10,000 testing images.  \n",
    "    test_iter: 100  \n",
    "    #Carry out testing every 500 training iterations. 设置每500次测试一下网络 精度 损失  \n",
    "    test_interval: 500  \n",
    "    #The base learning rate, momentum and the weight decay of the network.  \n",
    "    base_lr: 0.01  \n",
    "    momentum: 0.9  \n",
    "    weight_decay: 0.0005  \n",
    "    #The learning rate policy  \n",
    "    lr_policy: \"inv\"  \n",
    "    gamma: 0.0001  \n",
    "    power: 0.75   \n",
    "    #Display every 100 iterations  设置每100次迭代训练显示当前状态 lr loss  \n",
    "    display: 100  \n",
    "    #The maximum number of iterations   \n",
    "    max_iter: 10000  \n",
    "    #snapshot intermediate results中间结果快照每5000次保存一次  \n",
    "    snapshot: 5000  \n",
    "    snapshot_prefix: \"examples/mnist/lenet\"   \n",
    "    #solver mode: CPU or GPU  \n",
    "    solver_mode: GPU  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)训练  \n",
    "* 执行shell脚本，开始训练  \n",
    "./examples/mnist/train_lenet.sh  \n",
    "训练好的模型保存路径: examples/mnist  \n",
    "* 对训练结果进行测试：  \n",
    "./build/tools/caffe test -model examples/mnist/lenet_train_test.prototxt -weights examples/mnist/lenet_iter_10000.caffemodel  -iterations 100\n",
    "\n",
    "5)用python接口调用训练号的模型识别数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "caffe_root = 'your_caffe_path'\n",
    "sys.path.insert(0, caffe_root + 'python') #把pycaffe所在路径添加到环境变量 \n",
    "import caffe\n",
    "\n",
    "MODEL_FILE = os.pathjoin(caffe_root, 'examples/mnist/lenet.prototxt') \n",
    "PRETRAINED = os.pathjoin(caffe_root, 'examples/mnist/lenet_iter_10000.caffemodel') \n",
    "#图片处理成 lenet.prototxt的输入要求（尺寸28x28）且已经二值化为黑白色\n",
    "IMAGE_FILE = 'test.bmp'\n",
    " \n",
    "input_image = caffe.io.load_image(IMAGE_FILE, color=False)\n",
    "net = caffe.Classifier(MODEL_FILE, PRETRAINED) \n",
    "prediction = net.predict([input_image], oversample = False)\n",
    "caffe.set_mode_cpu()\n",
    "print('predicted class:', prediction[0].argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) TensorFlow的一些概念:  \n",
    "* 使用张量(tensor)表示数据. \n",
    "* 使用图(graph)来表示计算任务. \n",
    "* 在被称之为会话(Session)的上下文 (context)中执行图. \n",
    "* 通过变量 (Variable)维护状态. \n",
    "* 使用feed和fetch可以为任意的操作(arbitrary operation)赋值或者从其中获取数据   \n",
    "\n",
    "#### 2) 获取张量的值(使用eval属性)：   \n",
    "\n",
    "    x = tf.zeros((2,2))  \n",
    "    x.eval()  \n",
    "    输出：[[0 0] [0 0]]  \n",
    "    \n",
    "#### 3) Tensorflow的计算   \n",
    "  构造部分(计算流图) => 执行部分(通过session来执行图中的计算)\n",
    "* 定义计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# 创建一个常量节点， 产生一个1x2矩阵，这个op被作为一个节点\n",
    "# 加到默认视图中\n",
    "# 构造器的返回值代表该常量节点的返回值 \n",
    "matrix1 = tf.constant([[3,3]])\n",
    "# 创建另一个常量节点，产生一个2x1的矩阵 \n",
    "matrix2 = tf.constant([2],[2]).\n",
    "# 创建一个矩阵乘法matmu1节点，把matrix1和matrix2作为输入： \n",
    "product = tf.matmul(matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 通过TF中的session执行上面的操作  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建session，启动默认图 \n",
    "sess = tf.Session()  \n",
    "# 调用sess的'run()'方法来执行矩阵乘法节点操作, 传入'product'作为该方法的参数。'product'代表了矩阵乘法节点的输出，传人它是告诉方法我们希望取回矩阵乘法节点的输出。\n",
    "# 整个执行过程是自动化的，会话负责传递节点所需的全部输入。节点通常是并发执行的。\n",
    "# 函数调用'run(product)'会触发图中三个节点（上面提到的两个常量节点和一个矩阵乘法节点）的执行。\n",
    "# 返回值'result'是一个numpy 'ndarray'对象。\n",
    "result = sess.run(product) \n",
    "print(result)\n",
    "# 结果为[[12.]]\n",
    "# 完成任务, 记得关闭会话 \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 用with…device语句用来指派特定的CPU或GPU操作   \n",
    "with tf.device(\"/gpu:0\"):  \n",
    "/cpu:0 使用CPU  \n",
    "/gpu:0 使用编号为0的GPU  \n",
    "/gpu:1 使用编号为1的GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) TensorBoard 训练可视化  \n",
    "使用 tensorboard --lodir='./logs'命令将保存的日志文件进行可视化(例如：可视化loss/accuracy等)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5)TensorFlow实践  \n",
    "参考课件代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.PyTorch\n",
    "#### 特点\n",
    "* 高速计算  \n",
    "* 自动求导\n",
    "\n",
    "#### 基本概念  \n",
    "* torch.Tensor – 类似numpy.array的张量\n",
    "* autograd.Variable – 对Tensor的封装，可自动求导\n",
    "* autograd.Function – 对Variables的运算，完成前向(forward )和反向(backward)运算.\n",
    "* nn.Parameter – 一种特殊的Variable\n",
    "* nn.Module – 包含参数，以及输入变量上定义的函数\n",
    "\n",
    "#### 代码实践\n",
    "参考课件"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
